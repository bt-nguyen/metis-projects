{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame and Math Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Model Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metric Imports\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import imblearn.over_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models evaluation function\n",
    "def model_comparison(X, y):\n",
    "    \n",
    "    '''\n",
    "    X : data set features\n",
    "    y : data set target\n",
    "    folds : number of cross-validation fold\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Perform fit to each machine learning classifier\n",
    "    log = log_model.fit(X, y)\n",
    "    dtr = dtr_model.fit(X, y)\n",
    "    rfc = rfc_model.fit(X, y)\n",
    "    gnb = gnb_model.fit(X, y)\n",
    "    bnb = bnb_model.fit(X, y)\n",
    "    gbm = gbm_model.fit(X, y)\n",
    "    gbm_tuned = gbm_tuned_model.fit(X, y)\n",
    "    \n",
    "    # Perform fit to each machine learning classifier\n",
    "    log_predict = log_model.predict(X_test)\n",
    "    dtr_predict = dtr_model.predict(X_test)\n",
    "    rfc_predict = rfc_model.predict(X_test)\n",
    "    gnb_predict = gnb_model.predict(X_test)\n",
    "    bnb_predict = bnb_model.predict(X_test)\n",
    "    gbm_predict = gbm_model.predict(X_test)\n",
    "    gbm_tuned_predict = gbm_tuned_model.predict(X_test)\n",
    "    \n",
    "    # Create a data frame with the models perfomance metrics scores\n",
    "    models_scores_table = pd.DataFrame({'Logistic Regression':[accuracy_score(y_test, log_predict),\n",
    "                                                               precision_score(y_test, log_predict),\n",
    "                                                               recall_score(y_test, log_predict),\n",
    "                                                               f1_score(y_test, log_predict)],\n",
    "                                       \n",
    "                                      'Decision Tree':[accuracy_score(y_test, dtr_predict),\n",
    "                                                        precision_score(y_test, dtr_predict),\n",
    "                                                        recall_score(y_test, dtr_predict),\n",
    "                                                        f1_score(y_test, dtr_predict)],\n",
    "                                       \n",
    "                                      'Random Forest':[accuracy_score(y_test, rfc_predict),\n",
    "                                                        precision_score(y_test, rfc_predict),\n",
    "                                                        recall_score(y_test, rfc_predict),\n",
    "                                                        f1_score(y_test, rfc_predict)],\n",
    "                                       \n",
    "                                      'Bernoulli Naive Bayes':[accuracy_score(y_test, bnb_predict),\n",
    "                                                                precision_score(y_test, bnb_predict),\n",
    "                                                                recall_score(y_test, bnb_predict),\n",
    "                                                                f1_score(y_test, bnb_predict)],\n",
    "                                        \n",
    "                                    'Gaussian Naive Bayes':[accuracy_score(y_test, gnb_predict),\n",
    "                                                            precision_score(y_test, gnb_predict),\n",
    "                                                            recall_score(y_test, gnb_predict),\n",
    "                                                            f1_score(y_test, gnb_predict)],\n",
    "                                       \n",
    "                                       'XGradient Boost Classifier':[accuracy_score(y_test, gbm_predict),\n",
    "                                                                     precision_score(y_test, gbm_predict),\n",
    "                                                                     recall_score(y_test, gbm_predict),\n",
    "                                                                     f1_score(y_test, gbm_predict)],\n",
    "                                       \n",
    "                               'XGradient Boost Classifier (Tuned)':[accuracy_score(y_test, gbm_tuned_predict),\n",
    "                                                                     precision_score(y_test, gbm_tuned_predict),\n",
    "                                                                     recall_score(y_test, gbm_tuned_predict),\n",
    "                                                                     f1_score(y_test, gbm_tuned_predict)]},\n",
    "                                       \n",
    "                                       \n",
    "                                      \n",
    "                                      index = ['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    \n",
    "    # Add 'Best Score' column\n",
    "    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n",
    "    \n",
    "    # Print confusion matrix for each model\n",
    "    print('Logistic Regression: \\n', confusion_matrix(y_test, log_predict))\n",
    "    print('Decision Tree Classifier: \\n', confusion_matrix(y_test, dtr_predict))\n",
    "    print('Random Forest Classifier: \\n', confusion_matrix(y_test, rfc_predict))\n",
    "    print('Bernoulli Naive Bayes: \\n', confusion_matrix(y_test, bnb_predict))\n",
    "    print('Gaussian Naive Bayes: \\n', confusion_matrix(y_test, gnb_predict))\n",
    "    print('Extreme Gradient Boost: \\n', confusion_matrix(y_test, gbm_predict))\n",
    "    print('Extreme Gradient Boost (Tuned): \\n', confusion_matrix(y_test, gbm_tuned_predict))\n",
    "    \n",
    "    # Return models performance metrics scores data frame\n",
    "    return(models_scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models evaluation function\n",
    "def model_comparison_crossval(X, y, folds):\n",
    "    \n",
    "    '''\n",
    "    X : data set features\n",
    "    y : data set target\n",
    "    folds : number of cross-validation fold\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Define dictionary with performance metrics\n",
    "    scoring = {'accuracy':make_scorer(accuracy_score), \n",
    "               'precision':make_scorer(precision_score),\n",
    "               'recall':make_scorer(recall_score), \n",
    "               'f1_score':make_scorer(f1_score)}\n",
    "    \n",
    "    # Perform cross-validation to each machine learning classifier\n",
    "    log = cross_validate(log_model, X, y, cv = folds, scoring = scoring)\n",
    "    dtr = cross_validate(dtr_model, X, y, cv = folds, scoring = scoring)\n",
    "    rfc = cross_validate(rfc_model, X, y, cv = folds, scoring = scoring)\n",
    "    gnb = cross_validate(bnb_model, X, y, cv = folds, scoring = scoring)\n",
    "    bnb = cross_validate(gnb_model, X, y, cv = folds, scoring = scoring)\n",
    "    gbm = cross_validate(gbm_model, X, y, cv = folds, scoring = scoring)\n",
    "    gbm_tuned = cross_validate(gbm_tuned_model, X, y, cv = folds, scoring = scoring)\n",
    "    \n",
    "    # Perform cross-validation prediction to each machine learning classifier\n",
    "    log_predict = cross_val_predict(log_model, X, y, cv = folds)\n",
    "    dtr_predict = cross_val_predict(dtr_model, X, y, cv = folds)\n",
    "    rfc_predict = cross_val_predict(rfc_model, X, y, cv = folds)\n",
    "    bnb_predict = cross_val_predict(bnb_model, X, y, cv = folds)\n",
    "    gnb_predict = cross_val_predict(gnb_model, X, y, cv = folds)\n",
    "    gbm_predict = cross_val_predict(gbm_model, X, y, cv = folds)\n",
    "    gbm_tuned_predict = cross_val_predict(gbm_tuned_model, X, y, cv = folds)\n",
    "\n",
    "    # Create a data frame with the models perfomance metrics scores\n",
    "    models_scores_table = pd.DataFrame({'Logistic Regression':[log['test_accuracy'].mean(),\n",
    "                                                               log['test_precision'].mean(),\n",
    "                                                               log['test_recall'].mean(),\n",
    "                                                               log['test_f1_score'].mean()],\n",
    "                                       \n",
    "                                      'Decision Tree':[dtr['test_accuracy'].mean(),\n",
    "                                                       dtr['test_precision'].mean(),\n",
    "                                                       dtr['test_recall'].mean(),\n",
    "                                                       dtr['test_f1_score'].mean()],\n",
    "                                       \n",
    "                                      'Random Forest':[rfc['test_accuracy'].mean(),\n",
    "                                                       rfc['test_precision'].mean(),\n",
    "                                                       rfc['test_recall'].mean(),\n",
    "                                                       rfc['test_f1_score'].mean()],\n",
    "                                       \n",
    "                                      'Bernoulli Naive Bayes':[bnb['test_accuracy'].mean(),\n",
    "                                                               bnb['test_precision'].mean(),\n",
    "                                                               bnb['test_recall'].mean(),\n",
    "                                                               bnb['test_f1_score'].mean()],\n",
    "                                        \n",
    "                                    'Gaussian Naive Bayes':[gnb['test_accuracy'].mean(),\n",
    "                                                            gnb['test_precision'].mean(),\n",
    "                                                            gnb['test_recall'].mean(),\n",
    "                                                            gnb['test_f1_score'].mean()],\n",
    "                                       \n",
    "                                       'XGradient Boost Classifier':[gbm['test_accuracy'].mean(),\n",
    "                                                                     gbm['test_precision'].mean(),\n",
    "                                                                     gbm['test_recall'].mean(),\n",
    "                                                                     gbm['test_f1_score'].mean()],\n",
    "                                       \n",
    "                               'XGradient Boost Classifier (Tuned)':[gbm_tuned['test_accuracy'].mean(),\n",
    "                                                                     gbm_tuned['test_precision'].mean(),\n",
    "                                                                     gbm_tuned['test_recall'].mean(),\n",
    "                                                                     gbm_tuned['test_f1_score'].mean()]},\n",
    "                                      \n",
    "                                      index = ['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    \n",
    "    # Add 'Best Score' column\n",
    "    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n",
    "    \n",
    "    # Return models performance metrics scores data frame\n",
    "    return(models_scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import random as sparse_random\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of doc_topic_matrix:  (36261, 6)\n",
      "Shape of df to merge onto doc_topic_matrix:  (36261, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create two separate data frames for /r/onion and /r/nottheonion that are in EQUAL SAMPLE SIZE\n",
    "df = pd.read_csv('data/2020/doc_topic_matrix_2020.csv')\n",
    "df_tomerge = pd.read_csv('data/2020/merge_clean_2020.csv')\n",
    "\n",
    "print('Shape of doc_topic_matrix: ', df.shape)\n",
    "print('Shape of df to merge onto doc_topic_matrix: ', df_tomerge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_1  topic_2  topic_3  topic_4  topic_5  topic_6\n",
       "0      0.0  0.00001     -0.0  0.00003 -0.00001     -0.0\n",
       "1     -0.0  0.00000      0.0  0.00000 -0.00000     -0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onion</th>\n",
       "      <th>Title</th>\n",
       "      <th>Positive_Sentiment</th>\n",
       "      <th>Negative_Sentiment</th>\n",
       "      <th>Neutral_Sentiment</th>\n",
       "      <th>Compound_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mentally Unbalanced Man Still Waiting For The ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump Unable Produce Certificate Proving Not Pile</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onion                                              Title  \\\n",
       "0      1  Mentally Unbalanced Man Still Waiting For The ...   \n",
       "1      1  Trump Unable Produce Certificate Proving Not Pile   \n",
       "\n",
       "   Positive_Sentiment  Negative_Sentiment  Neutral_Sentiment  \\\n",
       "0                 0.0               0.000              1.000   \n",
       "1                 0.0               0.231              0.769   \n",
       "\n",
       "   Compound_Sentiment  \n",
       "0              0.0000  \n",
       "1             -0.5574  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tomerge.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes and do some fancy tricks to permit merging by resetting indexes\n",
    "df = pd.merge(df.reset_index(),\\\n",
    "         df_tomerge[['Positive_Sentiment', 'Negative_Sentiment', 'Neutral_Sentiment', 'Onion']].\\\n",
    "         reset_index()).drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>Positive_Sentiment</th>\n",
       "      <th>Negative_Sentiment</th>\n",
       "      <th>Neutral_Sentiment</th>\n",
       "      <th>Onion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  Positive_Sentiment  \\\n",
       "0      0.0  0.00001     -0.0  0.00003 -0.00001     -0.0                 0.0   \n",
       "1     -0.0  0.00000      0.0  0.00000 -0.00000     -0.0                 0.0   \n",
       "\n",
       "   Negative_Sentiment  Neutral_Sentiment  Onion  \n",
       "0               0.000              1.000      1  \n",
       "1               0.231              0.769      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows to /r/TheOnion (1):  1080\n",
      "Amount of rows to /r/NotTheOnion (0):  35181\n"
     ]
    }
   ],
   "source": [
    "print('Amount of rows to /r/TheOnion (1): ', len(df[df['Onion'] == 1]))\n",
    "print('Amount of rows to /r/NotTheOnion (0): ', len(df[df['Onion'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_n = 70000\n",
    "remove_n = 122890 # some factor of how many numbers to remove\n",
    "df = df.drop(np.random.choice(df.index[df['Onion'] == 0], remove_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows to /r/TheOnion (1):  1080\n",
      "Amount of rows to /r/NotTheOnion (0):  1075\n"
     ]
    }
   ],
   "source": [
    "print('Amount of rows to /r/TheOnion (1): ', len(df[df['Onion'] == 1]))\n",
    "print('Amount of rows to /r/NotTheOnion (0): ', len(df[df['Onion'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape (X): (2155, 9)\n",
      "Labels Shape (y): (2155,)\n",
      "Training Features Shape: (1724, 9)\n",
      "Training Labels Shape: (1724,)\n",
      "Testing Features Shape: (431, 9)\n",
      "Testing Labels Shape: (431,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :len(df.columns)-1]\n",
    "y = df.iloc[:, len(df.columns)-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :len(df.columns)-1],\n",
    "                                                    df.iloc[:, len(df.columns)-1], \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "print('Features Shape (X):', X.shape)\n",
    "print('Labels Shape (y):', y.shape)\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>Positive_Sentiment</th>\n",
       "      <th>Negative_Sentiment</th>\n",
       "      <th>Neutral_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  Positive_Sentiment  \\\n",
       "0      0.0  0.00001     -0.0  0.00003 -0.00001     -0.0                 0.0   \n",
       "1     -0.0  0.00000      0.0  0.00000 -0.00000     -0.0                 0.0   \n",
       "\n",
       "   Negative_Sentiment  Neutral_Sentiment  \n",
       "0               0.000              1.000  \n",
       "1               0.231              0.769  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup for the ratio argument of RandomOverSampler initialization\n",
    "# n_pos = np.sum(y_train == 1)\n",
    "# n_neg = np.sum(y_train == 0)\n",
    "# ratio = {1 : n_pos * 20, 0 : int(n_neg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Randomly oversample positive samples: create 10x as many \n",
    "# ROS = imblearn.over_sampling.RandomOverSampler(sampling_strategy = ratio, random_state = 42) \n",
    "\n",
    "# X_train_resample, y_train_resample = ROS.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Randomly oversample positive samples: create 10x as many \n",
    "# RUS = imblearn.under_sampling.RandomUnderSampler(sampling_strategy = ratio, random_state = 42) \n",
    "\n",
    "# X_train_resample, y_train_resample = RUS.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(max_iter = 5000,\n",
    "                               solver = 'liblinear',\n",
    "                               penalty = 'l1',\n",
    "                               C = 21.544346900318832)\n",
    "dtr_model = DecisionTreeClassifier()\n",
    "rfc_model = RandomForestClassifier()\n",
    "gnb_model = GaussianNB()\n",
    "bnb_model = BernoulliNB()\n",
    "gbm_model = xgb.XGBClassifier(objective = \"binary:logistic\")\n",
    "gbm_tuned_model = xgb.XGBClassifier(n_estimators = 5300,\n",
    "                                    max_depth = 1,\n",
    "                                    objective = \"binary:logistic\",\n",
    "                                    learning_rate = 0.1, \n",
    "                                    subsample = 1,\n",
    "                                    min_child_weight = 1,\n",
    "                                    colsample_bytree = 0.2,\n",
    "                                    scale_pos_weight = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      " [[151  74]\n",
      " [114  92]]\n",
      "Decision Tree Classifier: \n",
      " [[103 122]\n",
      " [ 95 111]]\n",
      "Random Forest Classifier: \n",
      " [[106 119]\n",
      " [ 87 119]]\n",
      "Bernoulli Naive Bayes: \n",
      " [[ 91 134]\n",
      " [ 50 156]]\n",
      "Gaussian Naive Bayes: \n",
      " [[  7 218]\n",
      " [  5 201]]\n",
      "Extreme Gradient Boost: \n",
      " [[106 119]\n",
      " [ 66 140]]\n",
      "Extreme Gradient Boost (Tuned): \n",
      " [[106 119]\n",
      " [ 63 143]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>XGradient Boost Classifier</th>\n",
       "      <th>XGradient Boost Classifier (Tuned)</th>\n",
       "      <th>Best Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.563805</td>\n",
       "      <td>0.496520</td>\n",
       "      <td>0.522042</td>\n",
       "      <td>0.573086</td>\n",
       "      <td>0.482599</td>\n",
       "      <td>0.570766</td>\n",
       "      <td>0.577726</td>\n",
       "      <td>XGradient Boost Classifier (Tuned)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.476395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.537931</td>\n",
       "      <td>0.479714</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.545802</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.446602</td>\n",
       "      <td>0.538835</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.975728</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.505695</td>\n",
       "      <td>0.536036</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Decision Tree  Random Forest  \\\n",
       "Accuracy              0.563805       0.496520       0.522042   \n",
       "Precision             0.554217       0.476395       0.500000   \n",
       "Recall                0.446602       0.538835       0.577670   \n",
       "F1 Score              0.494624       0.505695       0.536036   \n",
       "\n",
       "           Bernoulli Naive Bayes  Gaussian Naive Bayes  \\\n",
       "Accuracy                0.573086              0.482599   \n",
       "Precision               0.537931              0.479714   \n",
       "Recall                  0.757282              0.975728   \n",
       "F1 Score                0.629032              0.643200   \n",
       "\n",
       "           XGradient Boost Classifier  XGradient Boost Classifier (Tuned)  \\\n",
       "Accuracy                     0.570766                            0.577726   \n",
       "Precision                    0.540541                            0.545802   \n",
       "Recall                       0.679612                            0.694175   \n",
       "F1 Score                     0.602151                            0.611111   \n",
       "\n",
       "                                   Best Score  \n",
       "Accuracy   XGradient Boost Classifier (Tuned)  \n",
       "Precision                 Logistic Regression  \n",
       "Recall                   Gaussian Naive Bayes  \n",
       "F1 Score                 Gaussian Naive Bayes  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ask yourself: is minimizing false positives (not depressed, marked depressed--precision)\n",
    "              or false negatives (depressed, but not marked depressed--recall) more important?\n",
    "\n",
    "Answer: it is better to minimize false negatives and hence, a better RECALL score\n",
    "'''\n",
    "\n",
    "# Run basic model comparison with no oversampling\n",
    "\n",
    "model_comparison(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Run basic model comparison with 10x oversampling\n",
    "\n",
    "# model_comparison(X_train_resample, y_train_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>XGradient Boost Classifier</th>\n",
       "      <th>XGradient Boost Classifier (Tuned)</th>\n",
       "      <th>Best Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.546955</td>\n",
       "      <td>0.524997</td>\n",
       "      <td>0.552295</td>\n",
       "      <td>0.518568</td>\n",
       "      <td>0.556301</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>XGradient Boost Classifier (Tuned)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.571969</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>0.551688</td>\n",
       "      <td>0.513349</td>\n",
       "      <td>0.549068</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.572162</td>\n",
       "      <td>XGradient Boost Classifier (Tuned)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.424412</td>\n",
       "      <td>0.590556</td>\n",
       "      <td>0.627220</td>\n",
       "      <td>0.967973</td>\n",
       "      <td>0.700235</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.693508</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.486040</td>\n",
       "      <td>0.556950</td>\n",
       "      <td>0.586254</td>\n",
       "      <td>0.670849</td>\n",
       "      <td>0.615072</td>\n",
       "      <td>0.591105</td>\n",
       "      <td>0.626712</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Decision Tree  Random Forest  \\\n",
       "Accuracy              0.546955       0.524997       0.552295   \n",
       "Precision             0.571969       0.528053       0.551688   \n",
       "Recall                0.424412       0.590556       0.627220   \n",
       "F1 Score              0.486040       0.556950       0.586254   \n",
       "\n",
       "           Bernoulli Naive Bayes  Gaussian Naive Bayes  \\\n",
       "Accuracy                0.518568              0.556301   \n",
       "Precision               0.513349              0.549068   \n",
       "Recall                  0.967973              0.700235   \n",
       "F1 Score                0.670849              0.615072   \n",
       "\n",
       "           XGradient Boost Classifier  XGradient Boost Classifier (Tuned)  \\\n",
       "Accuracy                     0.540086                            0.580700   \n",
       "Precision                    0.538825                            0.572162   \n",
       "Recall                       0.655747                            0.693508   \n",
       "F1 Score                     0.591105                            0.626712   \n",
       "\n",
       "                                   Best Score  \n",
       "Accuracy   XGradient Boost Classifier (Tuned)  \n",
       "Precision  XGradient Boost Classifier (Tuned)  \n",
       "Recall                  Bernoulli Naive Bayes  \n",
       "F1 Score                Bernoulli Naive Bayes  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Run basic model comparison with K-fold = 5\n",
    "\n",
    "model_comparison_crossval(X_train, y_train, 10) #countvect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800, 9900, 10000, 10100, 10200, 10300, 10400, 10500, 10600, 10700, 10800, 10900, 11000], 'max_depth': [1, 2, 3, 4, 5], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is a setup for hyperparameter tuning.\n",
    "It uses a random grid search to find the 'best' hyperparamaters to use for random forest classification.\n",
    "'''\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 11000, num = 101)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 5, num = 5)]\n",
    "\n",
    "scale_pos_weight = [int(x) for x in np.linspace(1, 20, num = 20)]\n",
    "\n",
    "colsample_bytree = [round(x, 1) for x in np.linspace(0.2, 2.0, num = 10)]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'scale_pos_weight': scale_pos_weight,\n",
    "               'colsample_bytree': colsample_bytree}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1173 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1890 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.300000012,\n",
       "                                           max_delta_step=0, max_depth=6,\n",
       "                                           min_child_weight=1, missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=100, n_jobs=0,\n",
       "                                           num_p...\n",
       "                                                         2200, 2300, 2400, 2500,\n",
       "                                                         2600, 2700, 2800, 2900,\n",
       "                                                         3000, 3100, 3200, 3300,\n",
       "                                                         3400, 3500, 3600, 3700,\n",
       "                                                         3800, 3900, ...],\n",
       "                                        'scale_pos_weight': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20]},\n",
       "                   random_state=42, refit='accuracy_score',\n",
       "                   scoring={'accuracy_score': make_scorer(accuracy_score),\n",
       "                            'precision_score': make_scorer(precision_score),\n",
       "                            'recall_score': make_scorer(recall_score)},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This runs the hyperparameter tuning for random forest classification.\n",
    "# It takes about 30 minutes to run.\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 150 different combinations, and use all available cores\n",
    "\n",
    "scorers = {'precision_score': make_scorer(precision_score),\n",
    "           'recall_score': make_scorer(recall_score),\n",
    "           'accuracy_score': make_scorer(accuracy_score)}\n",
    "\n",
    "gbm_search = RandomizedSearchCV(estimator = gbm_model,\n",
    "                                param_distributions = random_grid,\n",
    "                                n_iter = 200, cv = 10, verbose = 2,\n",
    "                                random_state = 42,\n",
    "                                scoring = scorers, #Specifically optimizes accuracy\n",
    "                                refit = 'accuracy_score',\n",
    "                                n_jobs = -1)\n",
    "                                     \n",
    "# Fit the random search model\n",
    "gbm_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale_pos_weight': 1,\n",
       " 'n_estimators': 5300,\n",
       " 'max_depth': 1,\n",
       " 'colsample_bytree': 0.2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this after the above cell is run to collect best parameters\n",
    "gbm_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=166.81005372000593, penalty='l1', solver='saga')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to look through\n",
    "C = np.logspace(0, 4, num = 10)\n",
    "penalty = ['l1', 'l2']\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "# Create the random grid\n",
    "hyperparameters = dict(C=C, penalty=penalty, solver=solver)\n",
    "\n",
    "# Perform the search\n",
    "logistic = linear_model.LogisticRegression()\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters)\n",
    "\n",
    "best_model = gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=166.81005372000593, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
